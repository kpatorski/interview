[Back to interview](../interview.md)

# ğŸ”­ Observability â€” seeing what your system is really doing

<!-- TOC -->
* [ğŸ”­ Observability â€” seeing what your system is really doing](#-observability--seeing-what-your-system-is-really-doing)
  * [â„¹ï¸ What is Observability?](#â„¹-what-is-observability)
  * [â„¹ï¸ Popular observability frameworks & tools (ecosystem)](#â„¹-popular-observability-frameworks--tools-ecosystem)
  * [â„¹ï¸ The three pillars of observability](#â„¹-the-three-pillars-of-observability)
  * [ğŸ“œ Logs](#-logs)
    * [ğŸ”¸What are logs?](#what-are-logs)
    * [ğŸ”¸ When logs are useful](#-when-logs-are-useful)
    * [ğŸ”¸ Logging best practices](#-logging-best-practices)
  * [ğŸ“Š Metrics](#-metrics)
    * [ğŸ”¸ What are metrics?](#-what-are-metrics)
    * [ğŸ”¸ Metric types](#-metric-types)
    * [ğŸ”¸When metrics are useful](#when-metrics-are-useful)
    * [ğŸ”¸ Metrics best practices](#-metrics-best-practices)
  * [ğŸ§µ Tracing](#-tracing)
    * [ğŸ”¸ What is distributed tracing?](#-what-is-distributed-tracing)
    * [ğŸ”¸When tracing is useful](#when-tracing-is-useful)
    * [ğŸ”¸Tracing best practices](#tracing-best-practices)
  * [ğŸ§© Correlation pattern](#-correlation-pattern)
  * [Anti-patterns](#anti-patterns)
<!-- TOC -->

## â„¹ï¸ What is Observability?

Observability is the ability to:

> understand the internal state of a system by looking at its outputs

Those outputs are:

- Logs
- Metrics
- Traces

ğŸ“Œ Monitoring tells you something is wrong  
ğŸ“Œ Observability helps you answer why it is wrong  

## â„¹ï¸ Popular observability frameworks & tools (ecosystem)

ğŸ”¸ **Core standards / instrumentation**

- OpenTelemetry (OTel) â†’ unified standard for logs, metrics, traces

---

ğŸ”¸ **Metrics stack**

- Prometheus
- Grafana

---

ğŸ”¸ **Logging stack**

- ELK Stack (Elasticsearch, Logstash, Kibana)
- OpenSearch
- Loki (Grafana ecosystem)

---

ğŸ”¸ **Tracing**

- Jaeger
- Zipkin
- Tempo (Grafana ecosystem)

---

ğŸ”¸ **Commercial platforms (all-in-one)**

- Datadog
- New Relic
- Dynatrace
- Elastic Observability

---

## â„¹ï¸ The three pillars of observability

```bash
Logs    â†’ what happened?
Metrics â†’ how often / how bad?
Traces  â†’ where did it happen?
```

ğŸ“Œ They **complement**, not replace each other.

---
<div style="break-after: page;"></div>

## ğŸ“œ Logs

### ğŸ”¸What are logs?

Logs are:

- discrete events
- timestamped
- human-readable (usually)

**Example:**

```json
{
  "level": "ERROR",
  "service": "payment-service",
  "message": "Payment failed",
  "orderId": "123",
  "traceId": "abc-456"
}
```

### ğŸ”¸ When logs are useful

âœ… debugging edge cases  
âœ… investigating failures  
âœ… auditing  
âœ… understanding business flow  

### ğŸ”¸ Logging best practices

âœ… Structured logs (JSON, not plain text)  
âœ… Correlation IDs / trace IDs  
âœ… Log events, not control flow  
âœ… Avoid logging secrets  
âœ… Log at boundaries (IO, errors)  

âŒ Logging everything  
âŒ Using logs as metrics

---
<div style="break-after: page;"></div>

## ğŸ“Š Metrics

### ğŸ”¸ What are metrics?

Metrics are:

- numeric
- aggregated over time
- cheap to store
- cheap to query

**Examples:**

```css
http_requests_total
http_request_duration_seconds
cpu_usage
memory_usage
```

### ğŸ”¸ Metric types

| Type      | Meaning          | Example       |
|-----------|------------------|---------------|
| Counter   | always increases | request count |
| Gauge     | up & down        | memory        |
| Histogram | distribution     | latency       |
| Summary   | quantiles        | p95 latency   |

### ğŸ”¸When metrics are useful

âœ… alerting  
âœ… dashboards  
âœ… SLO / SLA tracking  
âœ… capacity planning  

ğŸ“Œ Metrics answer:

> â€œIs the system healthy?â€

### ğŸ”¸ Metrics best practices

âœ… Low cardinality labels  
âœ… Measure symptoms, not causes  
âœ… Use RED / USE methods  
âœ… Alert on user impact  

âŒ Per-user labels  
âŒ Logging as metrics  

---
<div style="break-after: page;"></div>

## ğŸ§µ Tracing

### ğŸ”¸ What is distributed tracing?

Tracing follows a single request across:

- services
- threads
- async boundaries

A trace consists of spans.

**Example trace**

```css
HTTP request
 â”œâ”€â”€ API Gateway
 â”œâ”€â”€ Order Service
 â”‚    â”œâ”€â”€ DB query
 â”‚    â””â”€â”€ Payment Service
 â”‚         â””â”€â”€ External API
```
Each span has:

- duration
- metadata
- parent/child relation

### ğŸ”¸When tracing is useful

âœ… microservices
âœ… latency analysis
âœ… bottleneck detection
âœ… debugging async flows

Tracing answers:

> â€œWhere exactly is time being spent?â€

### ğŸ”¸Tracing best practices

âœ… Propagate trace context everywhere
âœ… Sample intelligently
âœ… Combine traces with logs
âœ… Donâ€™t trace everything at 100%

---
<div style="break-after: page;"></div>

## ğŸ§© Correlation pattern

ğŸ“Œ **Rule#1:**

> Logs, metrics, and traces must share identifiers

```css
traceId
spanId
requestId
``` 
---

## Anti-patterns

âŒ Logging without context  
âŒ Metrics without alerts  
âŒ Alerts without runbooks  
âŒ Tracing without sampling strategy  
âŒ Dashboards no one looks at  

---
<div style="break-after: page;"></div>